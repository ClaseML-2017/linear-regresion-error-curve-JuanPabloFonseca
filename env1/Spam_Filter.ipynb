{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio de Bayes Ingenuo, Spam Filter\n",
    "### Juan Pablo Fonseca Correa  138263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importar librerías y leer la base de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sys import maxint\n",
    "from __future__ import division\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "df = pd.read_csv('spambase.data', sep=\",\",header = None) # leo la bd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numRows = df.shape[0] # num filas totales\n",
    "numCols = df.shape[1] # num columnas totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\juanpa~1\\desktop\\env1\\python~1\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# separar en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[df.columns[0:-1]],df[df.columns[-1]], train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numColsTrain = X_train.shape[0] # num filas para el train\n",
    "numColsTest = X_test.shape[0] # num filas para el test\n",
    "# aqui no voy a hacer conjunto de validacion, solo hice train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calcular P(Spam) y P(no Spam)\n",
    "probaSpam = len(Y_train.nonzero()[0])/len(Y_train)\n",
    "probaNoSpam = 1 - probaSpam\n",
    "\n",
    "# dentro del train, calcular promedios y desv estandar, dado que es o no Spam\n",
    "\n",
    "# UNA FORMA DE HACERLO (separando spam y no spam, y luego con un for)\n",
    "# dataTrainSpam = X_train[Y_train == 1]\n",
    "# dataTrainNoSpam = X_train[Y_train == 0]\n",
    "# promSpam = []\n",
    "# desvestSpam = []\n",
    "# promNoSpam = []\n",
    "# desvestNoSpam = []\n",
    "# for i in range(0,numCols-1):\n",
    "#     promSpam.append(dataTrainSpam.iloc[:,i].mean())\n",
    "#     desvestSpam.append(dataTrainSpam.iloc[:,i].std())\n",
    "#     promNoSpam.append(dataTrainNoSpam.iloc[:,i].mean())\n",
    "#     desvestNoSpam.append(dataTrainNoSpam.iloc[:,i].std())\n",
    "     # ya tienes todos los promedios y desviaciones estandar para calcular todas las probas de clase (dist. Normal)\n",
    "\n",
    "# OTRA FORMA MEJOR (todo junto):\n",
    "promSpam = np.mean(X_train[Y_train == 1], axis = 0) # axis = 0 es para promediar columnas (verticalmente pues)\n",
    "desvestSpam = np.std(X_train[Y_train == 1], axis = 0)\n",
    "promNoSpam = np.mean(X_train[Y_train == 0], axis = 0)\n",
    "desvestNoSpam = np.std(X_train[Y_train == 0], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ahora vamos a probar con el test\n",
    "logProbaSpam = math.log(probaSpam)\n",
    "logProbaNoSpam = math.log(probaNoSpam)\n",
    "clasifModelo = []\n",
    "clasifOriginal = Y_test\n",
    "normalesS = []\n",
    "normalesNS = []\n",
    "for j in range(0,numCols-1): # en este for guardo las normales que voy a utilizar\n",
    "    normalesS.append(norm(promSpam[j],desvestSpam[j]))\n",
    "    normalesNS.append(norm(promNoSpam[j],desvestNoSpam[j]))\n",
    "for i in range(0,len(Y_test)):\n",
    "    logProbaXDadoSpam = [] # log(P(Xi=xi|Spam)), para cada una de las Xi\n",
    "    logProbaXDadoNoSpam = [] # log(P(Xi=xi|no Spam)), para cada una de las Xi\n",
    "    for j in range(0,numCols-1):\n",
    "        if(desvestSpam[j]>0): # solo agregas log(P(Xi=xi|Spam)) si la desvest es mayor a 0 (aporta informacion)\n",
    "            normalDadoSpam=normalesS[j].pdf(X_test.iloc[i,j])\n",
    "            if(normalDadoSpam>0):\n",
    "                logProbaXDadoSpam.append(math.log(normalDadoSpam))\n",
    "            elif(normalDadoSpam==0): # para probabilidades que nos dan cero\n",
    "                logProbaXDadoSpam.append(-maxint - 1)\n",
    "            else:\n",
    "                print \"Sale una proba negativa! hay un error...\"\n",
    "        if(desvestNoSpam[j]>0):\n",
    "            normalDadoNoSpam=normalesNS[j].pdf(X_test.iloc[i,j])\n",
    "            if(normalDadoNoSpam>0):\n",
    "                logProbaXDadoNoSpam.append(math.log(normalDadoNoSpam))\n",
    "            elif(normalDadoNoSpam==0):\n",
    "                logProbaXDadoNoSpam.append(-maxint - 1)\n",
    "            else:\n",
    "                print \"Sale una proba negativa! hay un error...\"\n",
    "    valorSpam = logProbaSpam + np.sum(logProbaXDadoSpam)\n",
    "    valorNoSpam = logProbaNoSpam + np.sum(logProbaXDadoNoSpam)\n",
    "    if(valorSpam >= valorNoSpam):\n",
    "        clasifModelo.append(1)\n",
    "    else:\n",
    "        clasifModelo.append(0)\n",
    "\n",
    "# no sumas probabilidades = 0, y no sumas desvest = 0 ( es la solución del profe ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.724615384615\n",
      "Recall: 0.967145790554\n"
     ]
    }
   ],
   "source": [
    "# evaluación (aquí con precision y recall)\n",
    "truePositives = 0\n",
    "selected = 0\n",
    "relevant = 0\n",
    "\n",
    "for i in range(0,len(Y_test)):\n",
    "    if(clasifModelo[i] == 1 and clasifOriginal.values[i] == 1):\n",
    "        truePositives += 1\n",
    "    if(clasifModelo[i] == 1):\n",
    "        selected += 1\n",
    "    if(clasifOriginal.values[i] == 1):\n",
    "        relevant += 1\n",
    "precision = truePositives / selected\n",
    "recall = truePositives / relevant\n",
    "print 'Precision: {0}'.format(precision)\n",
    "print 'Recall: {0}'.format(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[485 179]\n",
      " [ 16 471]]\n",
      "Verdaderos negativos: 485\n",
      "Falsos positivos: 179\n",
      "Falsos negativos: 16\n",
      "Verdaderos positivos: 471\n"
     ]
    }
   ],
   "source": [
    "# evaluación con matriz de confusión\n",
    "mc = confusion_matrix(clasifOriginal,clasifModelo)\n",
    "print \"Matriz de confusión:\"\n",
    "print \"{0}\".format(mc)\n",
    "print \"Verdaderos negativos: {0}\".format(mc[0][0])\n",
    "print \"Falsos positivos: {0}\".format(mc[0][1])\n",
    "print \"Falsos negativos: {0}\".format(mc[1][0])\n",
    "print \"Verdaderos positivos: {0}\".format(mc[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
